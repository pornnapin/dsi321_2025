{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3003d44b-8d61-4433-ae5d-e2cd8d38cf6b",
   "metadata": {},
   "source": [
    "# **Check Data Quality**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591aae6c-f3cb-4a69-9245-8c00fa0d4dfc",
   "metadata": {},
   "source": [
    "## **Import libraries and Load data** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf697140-25b3-4dcc-ab9d-760e7d1524eb",
   "metadata": {},
   "source": [
    "#### **Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd08fff3-458d-46fc-8b44-09659508501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9bfd8f-963a-4eb7-bb54-79d006cfdeff",
   "metadata": {},
   "source": [
    "#### **Load All Parquet Files**\n",
    "* Reads all `.parquet` files from the specified path, covering all years, months, days and hours.\n",
    "* If no files are found, it raises a `FileNotFoundError`.\n",
    "* If files exist, they are concatenated into a single `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "835c6435-4dd4-4c87-aa18-fea86076f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"/home/jovyan/data/data.parquet/year=*/month=*/day=*/hour=*/*.parquet\")\n",
    "\n",
    "if len(files) == 0:\n",
    "    raise FileNotFoundError(\"❌ Can't find parquet in this path\")\n",
    "\n",
    "df = pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7414b17-c977-4cca-973c-b913d0e2bbac",
   "metadata": {},
   "source": [
    "## **Quality Check** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7688a-196b-45b6-ad46-a466576111a3",
   "metadata": {},
   "source": [
    "#### **Validate Dataset Schema**\n",
    "- Checks whether the dataset contains all the required columns.  \n",
    "- If any columns are missing, it raises a `ValueError` with the list of missing columns.  \n",
    "- If all required columns are present, it prints a verification message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65b0f95-244d-4209-a1cd-83a4f86b46c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Schema is correct.\n"
     ]
    }
   ],
   "source": [
    "expected_columns = [\n",
    "    \"timestamp\", \"stationID\", \"nameTH\", \"areaTH\", \"district\",\n",
    "    \"lat\", \"long\", \"AQI.aqi\", \"PM25.value\"\n",
    "]\n",
    "\n",
    "missing_columns = [col for col in expected_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"❌ Missing columns: {missing_columns}\")\n",
    "else:\n",
    "    print(\"\\n✅ Schema is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc76002-9cc6-4405-b901-9483ee167961",
   "metadata": {},
   "source": [
    "#### **Check Minimum Record Count (≥ 1,000 records)**\n",
    "- Ensures the dataset has at least 1,000 records.  \n",
    "- If the record count is lower than expected, it displays a warning message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7578af4c-ab0d-47f7-b12f-4c0e1d6c6bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Record count verified: 13,440 records.\n"
     ]
    }
   ],
   "source": [
    "if len(df) >= 1000:\n",
    "    print(f\"\\n✅ Record count verified: {len(df):,} records.\")\n",
    "else:\n",
    "    print(f\"\\n❌ Too few records: {len(df)} (need ≥ 1000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa3571-c98a-41b2-8d90-9107587b81aa",
   "metadata": {},
   "source": [
    "#### **Check 24-Hour Coverage**\n",
    "- This step verifies the **completeness of hourly data** for each calendar day in the dataset.\n",
    "- Converts `timestamp` to datetime, then extracts `year`, `month`, `day`, and `hour`.\n",
    "- Then, it groups the data by `(year, month, day)` and counts the number of unique `hour` values per day.\n",
    "- A complete day must contain exactly **24 distinct hourly records** (from 00 to 23).\n",
    "- If any day has fewer than 24 hours, the script will print the specific date along with the list of missing hour values.\n",
    "- If all days are complete, a verification message is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b6fd20-8f4f-406b-8a0a-f4ecb8c5b9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All days include complete 24-hour data records.\n"
     ]
    }
   ],
   "source": [
    "df_for_24_hrs = df.copy()\n",
    "df_for_24_hrs['timestamp'] = pd.to_datetime(df_for_24_hrs['timestamp'])\n",
    "\n",
    "df_for_24_hrs['year'] = df_for_24_hrs['timestamp'].dt.year\n",
    "df_for_24_hrs['month'] = df_for_24_hrs['timestamp'].dt.month\n",
    "df_for_24_hrs['day'] = df_for_24_hrs['timestamp'].dt.day\n",
    "df_for_24_hrs['hour'] = df_for_24_hrs['timestamp'].dt.hour\n",
    "\n",
    "grouped = df_for_24_hrs.groupby(['year', 'month', 'day'])['hour'].nunique()\n",
    "incomplete_days = grouped[grouped < 24]\n",
    "\n",
    "missing_hours = defaultdict(list)\n",
    "\n",
    "for (y, m, d), group_df in df_for_24_hrs.groupby(['year', 'month', 'day']):\n",
    "    hours = set(group_df['hour'])\n",
    "    expected_hours = set(range(24))\n",
    "    missing = sorted(expected_hours - hours)\n",
    "    if missing:\n",
    "        missing_hours[(y, m, d)] = missing\n",
    "\n",
    "if not missing_hours:\n",
    "    print(\"\\n✅ All days include complete 24-hour data records.\")\n",
    "else:\n",
    "    print(f\"\\n❌ Found {len(missing_hours)} incomplete day(s):\")\n",
    "    for (y, m, d), hours in missing_hours.items():\n",
    "        print(f\"\\n  - {y}-{m:02d}-{d:02d}: missing hours {hours}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacfd1bf-449a-48a5-a9b8-d2142e82f299",
   "metadata": {},
   "source": [
    "#### **Check Column Completeness (≥ 90.00 %)**\n",
    "- Calculates the percentage of non-null values for each column.  \n",
    "- If any column has less than 90.00 % completeness, it reports the column name and completeness percentage.  \n",
    "- If all columns are ≥ 90.00 % complete, a verification message is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "570dd7f2-42ca-44cb-807a-498feab86cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Column completeness (%) --\n",
      "\n",
      "timestamp  : 100.00 %\n",
      "\n",
      "stationID  : 100.00 %\n",
      "\n",
      "nameTH     : 100.00 %\n",
      "\n",
      "areaTH     : 100.00 %\n",
      "\n",
      "district   : 100.00 %\n",
      "\n",
      "lat        : 100.00 %\n",
      "\n",
      "long       : 100.00 %\n",
      "\n",
      "AQI.aqi    : 100.00 %\n",
      "\n",
      "PM25.value : 100.00 %\n",
      "\n",
      "✅ Completeness ≥ 90.00 % for all columns.\n"
     ]
    }
   ],
   "source": [
    "missing_ratio = df.isnull().mean()\n",
    "completeness_ratio = (1 - missing_ratio) * 100.00\n",
    "\n",
    "completeness_str = completeness_ratio.apply(lambda x: f\"{x:6.2f} %\")\n",
    "\n",
    "print(\"\\n-- Column completeness (%) --\")\n",
    "max_col_len = max(len(col) for col in completeness_str.index)\n",
    "for col, val in completeness_str.items():\n",
    "    print(f\"\\n{col.ljust(max_col_len)} : {val}\")\n",
    "\n",
    "incomplete_cols = completeness_ratio[completeness_ratio < 90.00]\n",
    "\n",
    "if incomplete_cols.empty:\n",
    "    print(\"\\n✅ Completeness ≥ 90.00 % for all columns.\")\n",
    "else:\n",
    "    print(\"\\n❌ Some columns have < 90.00 % completeness:\")\n",
    "    for col, val in incomplete_cols.items():\n",
    "        print(f\"{col.ljust(max_col_len)} : {val:6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb0c83-48e0-4e89-9410-c592b3031eb2",
   "metadata": {},
   "source": [
    "#### **Check for Object Columns**\n",
    "- Lists the data type of each column in the dataset.  \n",
    "- Checks if any columns are of type `object` \n",
    "- If no object-type columns are found, a verification message is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b60c06c-eeb0-4eb7-81ab-9c1c1a48c434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Column Data Types --\n",
      "\n",
      "timestamp  : datetime64[us]\n",
      "\n",
      "stationID  : string\n",
      "\n",
      "nameTH     : string\n",
      "\n",
      "areaTH     : string\n",
      "\n",
      "district   : string\n",
      "\n",
      "lat        : float64\n",
      "\n",
      "long       : float64\n",
      "\n",
      "AQI.aqi    : int64\n",
      "\n",
      "PM25.value : float64\n",
      "\n",
      "✅ No object-type columns found.\n"
     ]
    }
   ],
   "source": [
    "dtypes = df.dtypes.astype(str)\n",
    "max_col_len = max(len(col) for col in dtypes.index)\n",
    "\n",
    "print(\"\\n-- Column Data Types --\")\n",
    "for col, dtype in dtypes.items():\n",
    "    print(f\"\\n{col.ljust(max_col_len)} : {dtype}\")\n",
    "\n",
    "object_cols = dtypes[dtypes == 'object'].index.tolist()\n",
    "\n",
    "if not object_cols:\n",
    "    print(\"\\n✅ No object-type columns found.\")\n",
    "else:\n",
    "    print(f\"\\n❌ Found object-type columns: {object_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198fb5aa-90f4-4e01-9508-c23723a7fa46",
   "metadata": {},
   "source": [
    "#### **Check for Duplicate Rows**\n",
    "- Checks for fully duplicated rows in the dataset using `df.duplicated()`.  \n",
    "- Reports the number of duplicate rows found, or shows a verification message if none are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec540f36-dbce-431b-99a5-8048a1731696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ No duplicated rows found.\n"
     ]
    }
   ],
   "source": [
    "duplicate_count = df.duplicated().sum()\n",
    "if duplicate_count == 0:\n",
    "    print(\"\\n✅ No duplicated rows found.\")\n",
    "else:\n",
    "    print(f\"\\n❌ Found {duplicate_count} duplicate rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5de779-1f88-4062-8fd0-3cf07775639b",
   "metadata": {},
   "source": [
    "#### **Display DataFrame Summary**\n",
    "- Uses `df.info()` to display an overview of the dataset.\n",
    "- For a quick inspection of the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b4f0eb-54af-478d-b113-c92811955c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13440 entries, 0 to 13439\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   timestamp   13440 non-null  datetime64[us]\n",
      " 1   stationID   13440 non-null  string        \n",
      " 2   nameTH      13440 non-null  string        \n",
      " 3   areaTH      13440 non-null  string        \n",
      " 4   district    13440 non-null  string        \n",
      " 5   lat         13440 non-null  float64       \n",
      " 6   long        13440 non-null  float64       \n",
      " 7   AQI.aqi     13440 non-null  int64         \n",
      " 8   PM25.value  13440 non-null  float64       \n",
      "dtypes: datetime64[us](1), float64(3), int64(1), string(4)\n",
      "memory usage: 945.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
